{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PPUqQtVHKggi"
   },
   "source": [
    "# VGGish Audio Embedding Collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuhXsmvIKL62"
   },
   "source": [
    "This colab demonstrates how to extract the AudioSet embeddings, using a VGGish deep neural network (DNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAE4O-fK-RW2"
   },
   "source": [
    "# Importing and Testing the VGGish System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKSLc0bIB1QS"
   },
   "source": [
    "Based on the directions at: https://github.com/tensorflow/models/tree/master/research/audioset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.5.5 :: Anaconda custom (64-bit)\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1YVQb-MBiUx",
    "outputId": "cb57ab27-62e0-4cd4-b9a7-d69555600a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /anaconda/envs/py35/lib/python3.5/site-packages (18.0)\n",
      "Requirement already satisfied: numpy in /anaconda/envs/py35/lib/python3.5/site-packages (1.14.6)\n",
      "Requirement already satisfied: scipy in /anaconda/envs/py35/lib/python3.5/site-packages (1.1.0)\n",
      "Requirement already satisfied: resampy in /anaconda/envs/py35/lib/python3.5/site-packages (0.2.1)\n",
      "Requirement already satisfied: tensorflow-gpu in /anaconda/envs/py35/lib/python3.5/site-packages (1.11.0)\n",
      "Requirement already satisfied: six in /anaconda/envs/py35/lib/python3.5/site-packages (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.13 in /anaconda/envs/py35/lib/python3.5/site-packages (from resampy) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.32 in /anaconda/envs/py35/lib/python3.5/site-packages (from resampy) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /anaconda/envs/py35/lib/python3.5/site-packages (from resampy) (1.14.6)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (1.0.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (1.0.5)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (0.31.1)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (39.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (1.13.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (0.6.2)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorflow-gpu) (1.11.0)\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /anaconda/envs/py35/lib/python3.5/site-packages (from numba>=0.32->resampy) (0.23.1)\n",
      "Requirement already satisfied: h5py in /anaconda/envs/py35/lib/python3.5/site-packages (from keras-applications>=1.0.5->tensorflow-gpu) (2.7.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda/envs/py35/lib/python3.5/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu) (2.6.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install numpy scipy\n",
    "!pip install resampy tensorflow-gpu six "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-gpu                        1.11.0     \r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kN7yMJ3BBu_Q",
    "outputId": "4cefe4aa-c6d3-4d79-f347-e77c6198350c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'youtube-8m' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!sudo git clone https://github.com/google/youtube-8m.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOutr-RFCFfD",
    "outputId": "bcf49405-c05f-4656-947b-c948b454d545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yvradsmi\r\n"
     ]
    }
   ],
   "source": [
    "# Check to see where are in the kernel's file system.\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CVgYDQ2CG4K",
    "outputId": "2b2c923c-d310-4529-a3e5-eaeb8d52406b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  277M  100  277M    0     0   139M      0  0:00:01  0:00:01 --:--:--  139M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 73020  100 73020    0     0   300k      0 --:--:-- --:--:-- --:--:--  300k\n"
     ]
    }
   ],
   "source": [
    "# Grab the VGGish model\n",
    "!sudo curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "!sudo curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEl3w-RjCPwp",
    "outputId": "890e71da-c5f5-4642-dcea-cab5a51ab943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audioset_v1_embeddings\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.1\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.2\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.3\r\n",
      "Desktop\r\n",
      "features.tar.gz\r\n",
      "index.html\r\n",
      "model_new\r\n",
      "models\r\n",
      "notebooks\r\n",
      "-p\r\n",
      "R\r\n",
      "-v\r\n",
      "VGGish_Audioset_&_Audio_embedding_Tutorial.ipynb\r\n",
      "vggish_model.ckpt\r\n",
      "vggish_pca_params.npz\r\n",
      "youtube-8m\r\n"
     ]
    }
   ],
   "source": [
    "# Make sure we got the model data.\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oApFn6gzCvsa",
    "outputId": "dd20d037-942c-432b-8b13-9e67e625f012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2468M  100 2468M    0     0   169M      0  0:00:14  0:00:14 --:--:--  193M\n"
     ]
    }
   ],
   "source": [
    "# Copy the source files to the current directory.\n",
    "!sudo curl -O http://storage.googleapis.com/us_audioset/youtube_corpus/v1/features/features.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo tar -xzf features.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'models' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DaMrmOEvC7L4",
    "outputId": "c1b9dca8-a930-4f01-9390-110c314a0b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audioset_v1_embeddings\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.1\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.2\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.3\r\n",
      "Desktop\r\n",
      "features.tar.gz\r\n",
      "index.html\r\n",
      "model_new\r\n",
      "models\r\n",
      "notebooks\r\n",
      "-p\r\n",
      "R\r\n",
      "-v\r\n",
      "VGGish_Audioset_&_Audio_embedding_Tutorial.ipynb\r\n",
      "vggish_model.ckpt\r\n",
      "vggish_pca_params.npz\r\n",
      "youtube-8m\r\n"
     ]
    }
   ],
   "source": [
    "# Make sure the source files got copied correctly.\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbtPmmX-CTHB",
    "outputId": "6e548dd6-d500-4bf6-cded-b367da66d324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yvradsmi/models/research/audioset\n",
      "audioset_v1_embeddings\t\t\t vggish_model.ckpt\r\n",
      "cuda-repo-ubuntu1604_8.0.44-1_amd64.deb  vggish_params.py\r\n",
      "features.tar.gz\t\t\t\t vggish_pca_params.npz\r\n",
      "mel_features.py\t\t\t\t vggish_postprocess.py\r\n",
      "model_new\t\t\t\t vggish_slim.py\r\n",
      "models\t\t\t\t\t vggish_smoke_test.py\r\n",
      "README.md\t\t\t\t vggish_train_demo.py\r\n",
      "vggish_inference_demo.py\t\t youtube-8m\r\n",
      "vggish_input.py\r\n"
     ]
    }
   ],
   "source": [
    "# Verify the location of the AudioSet source files\n",
    "%cd models/research/audioset\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enabling GPU Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Ign:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Get:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Ign:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Get:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Ign:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Get:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Ign:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]\n",
      "Get:6 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B]\n",
      "Get:7 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]          \n",
      "Get:8 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]     \n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]                    \n",
      "Hit:9 http://azure.archive.ubuntu.com/ubuntu xenial InRelease                  \n",
      "Hit:10 http://azure.archive.ubuntu.com/ubuntu xenial-updates InRelease         \n",
      "Hit:11 http://azure.archive.ubuntu.com/ubuntu xenial-backports InRelease       \n",
      "Get:6 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B] \n",
      "Get:7 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]          \n",
      "Get:8 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]     \n",
      "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
      "Ign:13 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:14 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Hit:16 http://packages.microsoft.com/repos/vscode stable InRelease             \n",
      "Hit:17 https://nvidia.github.io/libnvidia-container/ubuntu16.04/amd64  InRelease\n",
      "Get:18 https://nvidia.github.io/nvidia-container-runtime/ubuntu16.04/amd64  InRelease [1,136 B]\n",
      "Get:19 https://nvidia.github.io/nvidia-docker/ubuntu16.04/amd64  InRelease [1,129 B]\n",
      "Hit:20 http://security.ubuntu.com/ubuntu xenial-security InRelease             \n",
      "Hit:21 https://download.docker.com/linux/ubuntu xenial InRelease         \n",
      "Ign:22 https://dl.bintray.com/sbt/debian  InRelease\n",
      "Hit:23 https://packages.microsoft.com/repos/azure-cli xenial InRelease\n",
      "Hit:24 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial InRelease\n",
      "Hit:25 https://packages.microsoft.com/ubuntu/16.04/prod xenial InRelease\n",
      "Get:26 https://dl.bintray.com/sbt/debian  Release [815 B]                   \n",
      "Hit:26 https://dl.bintray.com/sbt/debian  Release                              \n",
      "Ign:29 https://download.docker.com/linux/ubuntu $(lsb_release InRelease        \n",
      "Hit:32 http://ppa.launchpad.net/jonathonf/gcc-7.1/ubuntu xenial InRelease   \n",
      "Ign:33 https://download.docker.com/linux/ubuntu $(lsb_release Release          \n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Hit:35 http://ppa.launchpad.net/webupd8team/atom/ubuntu xenial InRelease\n",
      "Ign:36 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Hit:38 http://ppa.launchpad.net/x2go/stable/ubuntu xenial InRelease\n",
      "Ign:40 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:36 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:40 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:36 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:40 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:36 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:40 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:36 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:40 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Err:34 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "  404  Not Found\n",
      "Ign:36 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:40 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Fetched 5,277 B in 8s (625 B/s)                                                \n",
      "Reading package lists... Done\n",
      "W: The repository 'https://download.docker.com/linux/ubuntu $(lsb_release Release' does not have a Release file.\n",
      "N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.\n",
      "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
      "E: Failed to fetch https://download.docker.com/linux/ubuntu/dists/$(lsb_release/stable/binary-amd64/Packages  404  Not Found\n",
      "E: Some index files failed to download. They have been ignored, or old ones used instead.\n"
     ]
    }
   ],
   "source": [
    "#Install Docker\n",
    "!sudo -S apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "apt-transport-https is already the newest version (1.2.27).\n",
      "ca-certificates is already the newest version (20170717~16.04.1).\n",
      "curl is already the newest version (7.47.0-1ubuntu2.9).\n",
      "software-properties-common is already the newest version (0.96.20.7).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  bridge-utils ubuntu-fan\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo -S apt-get -y install \\\n",
    "    apt-transport-https \\\n",
    "    ca-certificates \\\n",
    "    curl \\\n",
    "    software-properties-common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo add-apt-repository \\\n",
    "   'deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n",
    "   $(lsb_release -cs) \\\n",
    "   stable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Ign:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Get:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Ign:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Get:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Ign:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Get:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Ign:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]\n",
      "Hit:6 http://azure.archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]                    \n",
      "Hit:7 http://azure.archive.ubuntu.com/ubuntu xenial-updates InRelease          \n",
      "Hit:8 http://azure.archive.ubuntu.com/ubuntu xenial-backports InRelease        \n",
      "Get:9 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B] \n",
      "Get:9 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B] \n",
      "Get:10 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]         \n",
      "Get:10 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]         \n",
      "Get:11 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]    \n",
      "Get:11 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]    \n",
      "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
      "Ign:13 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:14 http://packages.microsoft.com/repos/vscode stable InRelease             \n",
      "Hit:15 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Hit:16 https://nvidia.github.io/libnvidia-container/ubuntu16.04/amd64  InRelease\n",
      "Get:17 https://nvidia.github.io/nvidia-container-runtime/ubuntu16.04/amd64  InRelease [1,136 B]\n",
      "Hit:18 https://download.docker.com/linux/ubuntu xenial InRelease               \n",
      "Get:19 https://nvidia.github.io/nvidia-docker/ubuntu16.04/amd64  InRelease [1,129 B]\n",
      "Hit:20 http://security.ubuntu.com/ubuntu xenial-security InRelease             \n",
      "Ign:22 https://dl.bintray.com/sbt/debian  InRelease                            \n",
      "Hit:23 https://packages.microsoft.com/repos/azure-cli xenial InRelease\n",
      "Hit:24 https://packages.microsoft.com/ubuntu/16.04/prod xenial InRelease\n",
      "Ign:25 https://download.docker.com/linux/ubuntu $(lsb_release InRelease\n",
      "Get:26 https://dl.bintray.com/sbt/debian  Release [815 B]\n",
      "Hit:26 https://dl.bintray.com/sbt/debian  Release                           \n",
      "Hit:27 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial InRelease        \n",
      "Ign:29 https://download.docker.com/linux/ubuntu $(lsb_release Release       \n",
      "Ign:32 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Hit:33 http://ppa.launchpad.net/jonathonf/gcc-7.1/ubuntu xenial InRelease\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Hit:36 http://ppa.launchpad.net/webupd8team/atom/ubuntu xenial InRelease       \n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:38 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Hit:40 http://ppa.launchpad.net/x2go/stable/ubuntu xenial InRelease\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:32 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:38 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:32 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:38 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:32 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:38 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:32 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:38 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Err:32 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "  404  Not Found\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:38 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Fetched 5,277 B in 7s (700 B/s)                                                \n",
      "Reading package lists... Done\n",
      "W: The repository 'https://download.docker.com/linux/ubuntu $(lsb_release Release' does not have a Release file.\n",
      "N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.\n",
      "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
      "E: Failed to fetch https://download.docker.com/linux/ubuntu/dists/$(lsb_release/-cs)/binary-amd64/Packages  404  Not Found\n",
      "E: Some index files failed to download. They have been ignored, or old ones used instead.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "docker is already the newest version (1.5-1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  bridge-utils ubuntu-fan\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  pigz\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "Suggested packages:\n",
      "  debootstrap docker-doc rinse zfs-fuse | zfsutils\n",
      "The following packages will be REMOVED:\n",
      "  docker-ce nvidia-docker\n",
      "The following NEW packages will be installed:\n",
      "  docker.io\n",
      "0 upgraded, 1 newly installed, 2 to remove and 84 not upgraded.\n",
      "Need to get 0 B/17.1 MB of archives.\n",
      "After this operation, 122 MB disk space will be freed.\n",
      "Preconfiguring packages ...\n",
      "(Reading database ... 448267 files and directories currently installed.)\n",
      "Removing nvidia-docker (1.0.1-1) ...\n",
      "Purging NVIDIA volumes\n",
      "Removing docker-ce (18.06.1~ce~3-0~ubuntu) ...\n",
      "Processing triggers for man-db (2.7.5-1) ...\n",
      "Selecting previously unselected package docker.io.\n",
      "(Reading database ... 448044 files and directories currently installed.)\n",
      "Preparing to unpack .../docker.io_17.03.2-0ubuntu2~16.04.1_amd64.deb ...\n",
      "Unpacking docker.io (17.03.2-0ubuntu2~16.04.1) ...\n",
      "Processing triggers for man-db (2.7.5-1) ...\n",
      "Processing triggers for ureadahead (0.100.0-19) ...\n",
      "Processing triggers for systemd (229-4ubuntu21.2) ...\n",
      "Setting up docker.io (17.03.2-0ubuntu2~16.04.1) ...\n",
      "Installing new version of config file /etc/default/docker ...\n",
      "Installing new version of config file /etc/init.d/docker ...\n",
      "Installing new version of config file /etc/init/docker.conf ...\n",
      "Processing triggers for systemd (229-4ubuntu21.2) ...\n",
      "Processing triggers for ureadahead (0.100.0-19) ...\n",
      "Requirement already satisfied: docker in /anaconda/envs/py35/lib/python3.5/site-packages (3.5.0)\n",
      "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /anaconda/envs/py35/lib/python3.5/site-packages (from docker) (2.18.4)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from docker) (0.53.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from docker) (1.11.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.3.0 in /anaconda/envs/py35/lib/python3.5/site-packages (from docker) (0.3.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/envs/py35/lib/python3.5/site-packages (from requests!=2.18.0,>=2.14.2->docker) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/py35/lib/python3.5/site-packages (from requests!=2.18.0,>=2.14.2->docker) (2018.4.16)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda/envs/py35/lib/python3.5/site-packages (from requests!=2.18.0,>=2.14.2->docker) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda/envs/py35/lib/python3.5/site-packages (from requests!=2.18.0,>=2.14.2->docker) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install docker \n",
    "!sudo apt-get install -y docker.io\n",
    "!pip install docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  pigz\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -f -y install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker version 17.03.2-ce, build f5ec1e2\r\n"
     ]
    }
   ],
   "source": [
    "!sudo docker --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "wget is already the newest version (1.17.1-1ubuntu1.4).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  pigz\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "#Install NVIDIA Drivers\n",
    "!sudo apt-get install -y wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-30 23:30:33--  http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.44-1_amd64.deb\r\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.211.70, 2606:2800:21f:3aa:dcf:37b:1ed6:1fb\r\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.211.70|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2690 (2.6K) [application/x-deb]\r\n",
      "Saving to: ‘cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.1’\r\n",
      "\r\n",
      "\r",
      "          cuda-repo   0%[                    ]       0  --.-KB/s               \r",
      "cuda-repo-ubuntu160 100%[===================>]   2.63K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2018-09-30 23:30:33 (524 MB/s) - ‘cuda-repo-ubuntu1604_8.0.44-1_amd64.deb.1’ saved [2690/2690]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!sudo wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.44-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 448141 files and directories currently installed.)\n",
      "Preparing to unpack cuda-repo-ubuntu1604_8.0.44-1_amd64.deb ...\n",
      "Unpacking cuda-repo-ubuntu1604 (8.0.44-1) over (8.0.44-1) ...\n",
      "Setting up cuda-repo-ubuntu1604 (8.0.44-1) ...\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!sudo dpkg -i --force-confdef cuda-repo-ubuntu1604_8.0.44-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Ign:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Get:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Ign:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Get:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Ign:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Get:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Ign:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]\n",
      "Get:6 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B]\n",
      "Get:7 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]          \n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]                    \n",
      "Get:8 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]     \n",
      "Get:6 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B] \n",
      "Get:7 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]          \n",
      "Get:8 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]     \n",
      "Get:9 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
      "Hit:11 http://azure.archive.ubuntu.com/ubuntu xenial InRelease                 \n",
      "Hit:12 http://azure.archive.ubuntu.com/ubuntu xenial-updates InRelease         \n",
      "Hit:13 http://azure.archive.ubuntu.com/ubuntu xenial-backports InRelease       \n",
      "Hit:14 https://download.docker.com/linux/ubuntu xenial InRelease               \n",
      "Ign:15 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:16 https://nvidia.github.io/libnvidia-container/ubuntu16.04/amd64  InRelease\n",
      "Get:17 https://nvidia.github.io/nvidia-container-runtime/ubuntu16.04/amd64  InRelease [1,136 B]\n",
      "Get:18 https://nvidia.github.io/nvidia-docker/ubuntu16.04/amd64  InRelease [1,129 B]\n",
      "Hit:19 http://packages.microsoft.com/repos/vscode stable InRelease             \n",
      "Hit:20 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Ign:21 https://dl.bintray.com/sbt/debian  InRelease                    \n",
      "Hit:23 https://packages.microsoft.com/repos/azure-cli xenial InRelease \n",
      "Hit:24 https://packages.microsoft.com/ubuntu/16.04/prod xenial InRelease\n",
      "Hit:25 http://security.ubuntu.com/ubuntu xenial-security InRelease     \n",
      "Hit:26 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial InRelease   \n",
      "Ign:27 https://download.docker.com/linux/ubuntu $(lsb_release InRelease\n",
      "Get:29 https://dl.bintray.com/sbt/debian  Release [815 B]                   \n",
      "Hit:29 https://dl.bintray.com/sbt/debian  Release                              \n",
      "Ign:31 https://download.docker.com/linux/ubuntu $(lsb_release Release          \n",
      "Hit:32 http://ppa.launchpad.net/jonathonf/gcc-7.1/ubuntu xenial InRelease     \n",
      "Ign:33 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Hit:36 http://ppa.launchpad.net/webupd8team/atom/ubuntu xenial InRelease\n",
      "Hit:38 http://ppa.launchpad.net/x2go/stable/ubuntu xenial InRelease            \n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:33 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:33 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:33 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:33 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Err:33 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "  404  Not Found\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Fetched 5,277 B in 8s (634 B/s)                                                \n",
      "Reading package lists... Done\n",
      "W: The repository 'https://download.docker.com/linux/ubuntu $(lsb_release Release' does not have a Release file.\n",
      "N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.\n",
      "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
      "E: Failed to fetch https://download.docker.com/linux/ubuntu/dists/$(lsb_release/-cs)/binary-amd64/Packages  404  Not Found\n",
      "E: Some index files failed to download. They have been ignored, or old ones used instead.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "cuda is already the newest version (10.0.130-1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  pigz\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -y install cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  pigz\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -f -y install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  bridge-utils ubuntu-fan\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "The following additional packages will be installed:\n",
      "  docker-ce\n",
      "The following packages will be REMOVED:\n",
      "  docker.io\n",
      "The following NEW packages will be installed:\n",
      "  docker-ce nvidia-docker\n",
      "0 upgraded, 2 newly installed, 1 to remove and 84 not upgraded.\n",
      "Need to get 0 B/42.3 MB of archives.\n",
      "After this operation, 122 MB of additional disk space will be used.\n",
      "(Reading database ... 448141 files and directories currently installed.)\n",
      "Removing docker.io (17.03.2-0ubuntu2~16.04.1) ...\n",
      "'/usr/share/docker.io/contrib/nuke-graph-directory.sh' -> '/var/lib/docker/nuke-graph-directory.sh'\n",
      "Processing triggers for man-db (2.7.5-1) ...\n",
      "Selecting previously unselected package docker-ce.\n",
      "(Reading database ... 448044 files and directories currently installed.)\n",
      "Preparing to unpack .../docker-ce_18.06.1~ce~3-0~ubuntu_amd64.deb ...\n",
      "Unpacking docker-ce (18.06.1~ce~3-0~ubuntu) ...\n",
      "Selecting previously unselected package nvidia-docker.\n",
      "Preparing to unpack .../nvidia-docker_1.0.1-1_amd64.deb ...\n",
      "Unpacking nvidia-docker (1.0.1-1) ...\n",
      "Processing triggers for man-db (2.7.5-1) ...\n",
      "Processing triggers for systemd (229-4ubuntu21.2) ...\n",
      "Processing triggers for ureadahead (0.100.0-19) ...\n",
      "Setting up docker-ce (18.06.1~ce~3-0~ubuntu) ...\n",
      "Installing new version of config file /etc/default/docker ...\n",
      "Installing new version of config file /etc/init.d/docker ...\n",
      "Installing new version of config file /etc/init/docker.conf ...\n",
      "Setting up nvidia-docker (1.0.1-1) ...\n",
      "Setting up permissions\n",
      "Processing triggers for systemd (229-4ubuntu21.2) ...\n",
      "Processing triggers for ureadahead (0.100.0-19) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y nvidia-docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Ign:1 file:/var/nccl-repo-2.1.4-ga-cuda9.0  InRelease\n",
      "Get:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Ign:2 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  InRelease\n",
      "Get:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Ign:3 file:/var/nvidia-diag-driver-local-repo-390.46  InRelease\n",
      "Get:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Ign:4 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  InRelease\n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]\n",
      "Hit:6 http://azure.archive.ubuntu.com/ubuntu xenial InRelease\n",
      "Hit:7 http://azure.archive.ubuntu.com/ubuntu xenial-updates InRelease\n",
      "Hit:8 http://azure.archive.ubuntu.com/ubuntu xenial-backports InRelease\n",
      "Get:5 file:/var/nccl-repo-2.1.4-ga-cuda9.0  Release [574 B]                    \n",
      "Get:9 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B] \n",
      "Get:9 file:/var/nv-tensorrt-repo-ga-cuda9.0-trt3.0.2-20180108  Release [574 B] \n",
      "Get:10 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]         \n",
      "Get:11 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]    \n",
      "Get:10 file:/var/nvidia-diag-driver-local-repo-390.46  Release [574 B]         \n",
      "Get:11 file:/var/nvinfer-runtime-trt-repo-3.0.4-ga-cuda9.0  Release [574 B]    \n",
      "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
      "Ign:13 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:14 http://packages.microsoft.com/repos/vscode stable InRelease             \n",
      "Hit:15 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Hit:16 https://nvidia.github.io/libnvidia-container/ubuntu16.04/amd64  InRelease\n",
      "Get:17 https://nvidia.github.io/nvidia-container-runtime/ubuntu16.04/amd64  InRelease [1,136 B]\n",
      "Get:18 https://nvidia.github.io/nvidia-docker/ubuntu16.04/amd64  InRelease [1,129 B]\n",
      "Hit:19 https://download.docker.com/linux/ubuntu xenial InRelease               \n",
      "Ign:20 https://dl.bintray.com/sbt/debian  InRelease                            \n",
      "Hit:21 https://packages.microsoft.com/repos/azure-cli xenial InRelease  \n",
      "Hit:22 https://packages.microsoft.com/ubuntu/16.04/prod xenial InRelease\n",
      "Get:23 https://dl.bintray.com/sbt/debian  Release [815 B]              \n",
      "Hit:23 https://dl.bintray.com/sbt/debian  Release                              \n",
      "Hit:24 http://ppa.launchpad.net/git-core/ppa/ubuntu xenial InRelease           \n",
      "Hit:25 http://security.ubuntu.com/ubuntu xenial-security InRelease     \n",
      "Ign:27 https://download.docker.com/linux/ubuntu $(lsb_release InRelease     \n",
      "Ign:30 https://download.docker.com/linux/ubuntu $(lsb_release Release       \n",
      "Hit:32 http://ppa.launchpad.net/jonathonf/gcc-7.1/ubuntu xenial InRelease   \n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Hit:36 http://ppa.launchpad.net/webupd8team/atom/ubuntu xenial InRelease\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Hit:40 http://ppa.launchpad.net/x2go/stable/ubuntu xenial InRelease\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Ign:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Err:34 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) amd64 Packages\n",
      "  404  Not Found\n",
      "Ign:35 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) all Packages\n",
      "Ign:37 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en_US\n",
      "Ign:39 https://download.docker.com/linux/ubuntu $(lsb_release/-cs) Translation-en\n",
      "Ign:41 https://download.docker.com/linux/ubuntu $(lsb_release/stable amd64 Packages\n",
      "Ign:42 https://download.docker.com/linux/ubuntu $(lsb_release/stable all Packages\n",
      "Ign:43 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en_US\n",
      "Ign:44 https://download.docker.com/linux/ubuntu $(lsb_release/stable Translation-en\n",
      "Fetched 5,277 B in 7s (662 B/s)                                                \n",
      "Reading package lists... Done\n",
      "W: The repository 'https://download.docker.com/linux/ubuntu $(lsb_release Release' does not have a Release file.\n",
      "N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.\n",
      "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
      "E: Failed to fetch https://download.docker.com/linux/ubuntu/dists/$(lsb_release/-cs)/binary-amd64/Packages  404  Not Found\n",
      "E: Some index files failed to download. They have been ignored, or old ones used instead.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 30 23:31:49 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00006DE9:00:00.0 Off |                    0 |\r\n",
      "| N/A   38C    P8    34W / 149W |     11MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "#!sudo nvidia-docker run --rm nvidia/cuda nvidia-smi\n",
    "!/usr/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZb1ohlU2NXr"
   },
   "source": [
    "# Audioset Embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "cC4tZrfAoyt8",
    "outputId": "bb8c08b0-a951-4dac-f6bf-f81ada1d7268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2468M  100 2468M    0     0   133M      0  0:00:18  0:00:18 --:--:--  160M\n"
     ]
    }
   ],
   "source": [
    "!sudo curl -O https://storage.googleapis.com/us_audioset/youtube_corpus/v1/features/features.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6xKmtqdpJ_w"
   },
   "outputs": [],
   "source": [
    "#Unpack the Audioset Features\n",
    "!sudo tar -xzf features.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JM0ZjuAJppwv",
    "outputId": "e8636638-0ff2-4f2e-9a4e-0d4268c83cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yvradsmi/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd /home/yvradsmi/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42maudioset_v1_embeddings\u001b[0m/\r\n",
      "\u001b[34;42mazureml\u001b[0m/\r\n",
      "\u001b[34;42mBatchAI\u001b[0m/\r\n",
      "\u001b[34;42mcaffe2\u001b[0m/\r\n",
      "\u001b[34;42mcatboost\u001b[0m/\r\n",
      "\u001b[34;42mChainer\u001b[0m/\r\n",
      "\u001b[34;42mCNTK\u001b[0m/\r\n",
      "\u001b[01;31mcuda-repo-ubuntu1604_8.0.44-1_amd64.deb\u001b[0m\r\n",
      "\u001b[34;42mdeep_water\u001b[0m/\r\n",
      "\u001b[01;32mDocumentDBSample.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mfeatures.tar.gz\u001b[0m*\r\n",
      "\u001b[34;42mh2o\u001b[0m/\r\n",
      "\u001b[01;32mIDEAR.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroduction to Azure ML R notebooks.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroduction to Microsoft R Operationalization.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroToJupyterPython.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroTutorialinMicrosoftR.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroTutorialinR.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIrisClassifierPyMLWebService.ipynb\u001b[0m*\r\n",
      "\u001b[34;42mjulia\u001b[0m/\r\n",
      "\u001b[01;32mLoadDataIntoDW.ipynb\u001b[0m*\r\n",
      "\u001b[34;42mMMLSpark\u001b[0m/\r\n",
      "\u001b[01;34mmodel_new\u001b[0m/\r\n",
      "\u001b[34;42mmodels\u001b[0m/\r\n",
      "\u001b[34;42mmxnet\u001b[0m/\r\n",
      "\u001b[01;32mpassword\u001b[0m*\r\n",
      "\u001b[34;42mpytorch\u001b[0m/\r\n",
      "\u001b[01;32mreaders.py\u001b[0m*\r\n",
      "\u001b[34;42mSparkML\u001b[0m/\r\n",
      "\u001b[01;32mSQLDW_Explorations.ipynb\u001b[0m*\r\n",
      "\u001b[34;42mtensorflow\u001b[0m/\r\n",
      "\u001b[01;32mVGGish_Audioset_&_Audio_embedding_Tutorial.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mvggish_model.ckpt\u001b[0m*\r\n",
      "\u001b[01;32mvggish_pca_params.npz\u001b[0m*\r\n",
      "\u001b[34;42myoutube-8m\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rF39FQ0_qdA_",
    "outputId": "a3de180a-d837-4446-db43-1e1fae1ede93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yvradsmi/notebooks/youtube-8m\n"
     ]
    }
   ],
   "source": [
    "cd youtube-8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chmod -R 777 /home/yvradsmi/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVsOSokZsgjI"
   },
   "outputs": [],
   "source": [
    "!sudo rm -f readers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing readers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile readers.py\n",
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS-IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Provides readers configured for different datasets.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "from tensorflow import logging\n",
    "def resize_axis(tensor, axis, new_size, fill_value=0):\n",
    "  \"\"\"Truncates or pads a tensor to new_size on on a given axis.\n",
    "  Truncate or extend tensor such that tensor.shape[axis] == new_size. If the\n",
    "  size increases, the padding will be performed at the end, using fill_value.\n",
    "  Args:\n",
    "    tensor: The tensor to be resized.\n",
    "    axis: An integer representing the dimension to be sliced.\n",
    "    new_size: An integer or 0d tensor representing the new value for\n",
    "      tensor.shape[axis].\n",
    "    fill_value: Value to use to fill any new entries in the tensor. Will be\n",
    "      cast to the type of tensor.\n",
    "  Returns:\n",
    "    The resized tensor.\n",
    "  \"\"\"\n",
    "  tensor = tf.convert_to_tensor(tensor)\n",
    "  shape = tf.unstack(tf.shape(tensor))\n",
    "\n",
    "  pad_shape = shape[:]\n",
    "  pad_shape[axis] = tf.maximum(0, new_size - shape[axis])\n",
    "\n",
    "  shape[axis] = tf.minimum(shape[axis], new_size)\n",
    "  shape = tf.stack(shape)\n",
    "\n",
    "  resized = tf.concat([\n",
    "      tf.slice(tensor, tf.zeros_like(shape), shape),\n",
    "      tf.fill(tf.stack(pad_shape), tf.cast(fill_value, tensor.dtype))\n",
    "  ], axis)\n",
    "\n",
    "  # Update shape.\n",
    "  new_shape = tensor.get_shape().as_list()  # A copy is being made.\n",
    "  new_shape[axis] = new_size\n",
    "  resized.set_shape(new_shape)\n",
    "  return resized\n",
    "\n",
    "class BaseReader(object):\n",
    "  \"\"\"Inherit from this class when implementing new readers.\"\"\"\n",
    "\n",
    "  def prepare_reader(self, unused_filename_queue):\n",
    "    \"\"\"Create a thread for generating prediction and label tensors.\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "class YT8MAggregatedFeatureReader(BaseReader):\n",
    "  \"\"\"Reads TFRecords of pre-aggregated Examples.\n",
    "  The TFRecords must contain Examples with a sparse int64 'labels' feature and\n",
    "  a fixed length float32 feature, obtained from the features in 'feature_name'.\n",
    "  The float features are assumed to be an average of dequantized values.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_classes=527,\n",
    "               feature_sizes=[1024, 128],\n",
    "               feature_names=[\"mean_rgb\", \"mean_audio\"]):\n",
    "    \"\"\"Construct a YT8MAggregatedFeatureReader.\n",
    "    Args:\n",
    "      num_classes: a positive integer for the number of classes.\n",
    "      feature_sizes: positive integer(s) for the feature dimensions as a list.\n",
    "      feature_names: the feature name(s) in the tensorflow record as a list.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(feature_names) == len(feature_sizes), \\\n",
    "    \"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\n",
    "    len(feature_names), len(feature_sizes))\n",
    "\n",
    "    self.num_classes = num_classes\n",
    "    self.feature_sizes = feature_sizes\n",
    "    self.feature_names = feature_names\n",
    "\n",
    "  def prepare_reader(self, filename_queue, batch_size=1024):\n",
    "    \"\"\"Creates a single reader thread for pre-aggregated YouTube 8M Examples.\n",
    "    Args:\n",
    "      filename_queue: A tensorflow queue of filename locations.\n",
    "    Returns:\n",
    "      A tuple of video indexes, features, labels, and padding data.\n",
    "    \"\"\"\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_examples = reader.read_up_to(filename_queue, batch_size)\n",
    "\n",
    "    tf.add_to_collection(\"serialized_examples\", serialized_examples)\n",
    "    return self.prepare_serialized_examples(serialized_examples)\n",
    "\n",
    "  def prepare_serialized_examples(self, serialized_examples):\n",
    "    # set the mapping from the fields to data types in the proto\n",
    "    num_features = len(self.feature_names)\n",
    "    assert num_features > 0, \"self.feature_names is empty!\"\n",
    "    assert len(self.feature_names) == len(self.feature_sizes), \\\n",
    "    \"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\n",
    "    len(self.feature_names), len(self.feature_sizes))\n",
    "\n",
    "    feature_map = {\"video_id\": tf.FixedLenFeature([], tf.string),\n",
    "                   \"labels\": tf.VarLenFeature(tf.int64)}\n",
    "    for feature_index in range(num_features):\n",
    "      feature_map[self.feature_names[feature_index]] = tf.FixedLenFeature(\n",
    "          [self.feature_sizes[feature_index]], tf.float32)\n",
    "\n",
    "    features = tf.parse_example(serialized_examples, features=feature_map)\n",
    "    labels = tf.sparse_to_indicator(features[\"labels\"], self.num_classes)\n",
    "    labels.set_shape([None, self.num_classes])\n",
    "    concatenated_features = tf.concat([\n",
    "        features[feature_name] for feature_name in self.feature_names], 1)\n",
    "\n",
    "    return features[\"video_id\"], concatenated_features, labels, tf.ones([tf.shape(serialized_examples)[0]])\n",
    "\n",
    "class YT8MFrameFeatureReader(BaseReader):\n",
    "  \"\"\"Reads TFRecords of SequenceExamples.\n",
    "  The TFRecords must contain SequenceExamples with the sparse in64 'labels'\n",
    "  context feature and a fixed length byte-quantized feature vector, obtained\n",
    "  from the features in 'feature_names'. The quantized features will be mapped\n",
    "  back into a range between min_quantized_value and max_quantized_value.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               num_classes=527,\n",
    "               feature_sizes=[1024, 128],\n",
    "               feature_names=[\"rgb\", \"audio\"],\n",
    "               max_frames=300):\n",
    "    \"\"\"Construct a YT8MFrameFeatureReader.\n",
    "    Args:\n",
    "      num_classes: a positive integer for the number of classes.\n",
    "      feature_sizes: positive integer(s) for the feature dimensions as a list.\n",
    "      feature_names: the feature name(s) in the tensorflow record as a list.\n",
    "      max_frames: the maximum number of frames to process.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(feature_names) == len(feature_sizes), \\\n",
    "    \"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\n",
    "    len(feature_names), len(feature_sizes))\n",
    "\n",
    "    self.num_classes = num_classes\n",
    "    self.feature_sizes = feature_sizes\n",
    "    self.feature_names = feature_names\n",
    "    self.max_frames = max_frames\n",
    "\n",
    "  def get_video_matrix(self,\n",
    "                       features,\n",
    "                       feature_size,\n",
    "                       max_frames,\n",
    "                       max_quantized_value,\n",
    "                       min_quantized_value):\n",
    "    \"\"\"Decodes features from an input string and quantizes it.\n",
    "    Args:\n",
    "      features: raw feature values\n",
    "      feature_size: length of each frame feature vector\n",
    "      max_frames: number of frames (rows) in the output feature_matrix\n",
    "      max_quantized_value: the maximum of the quantized value.\n",
    "      min_quantized_value: the minimum of the quantized value.\n",
    "    Returns:\n",
    "      feature_matrix: matrix of all frame-features\n",
    "      num_frames: number of frames in the sequence\n",
    "    \"\"\"\n",
    "    decoded_features = tf.reshape(\n",
    "        tf.cast(tf.decode_raw(features, tf.uint8), tf.float32),\n",
    "        [-1, feature_size])\n",
    "\n",
    "    num_frames = tf.minimum(tf.shape(decoded_features)[0], max_frames)\n",
    "    feature_matrix = utils.Dequantize(decoded_features,\n",
    "                                      max_quantized_value,\n",
    "                                      min_quantized_value)\n",
    "    feature_matrix = resize_axis(feature_matrix, 0, max_frames)\n",
    "    return feature_matrix, num_frames\n",
    "\n",
    "  def prepare_reader(self,\n",
    "                     filename_queue,\n",
    "                     max_quantized_value=2,\n",
    "                     min_quantized_value=-2):\n",
    "    \"\"\"Creates a single reader thread for YouTube8M SequenceExamples.\n",
    "    Args:\n",
    "      filename_queue: A tensorflow queue of filename locations.\n",
    "      max_quantized_value: the maximum of the quantized value.\n",
    "      min_quantized_value: the minimum of the quantized value.\n",
    "    Returns:\n",
    "      A tuple of video indexes, video features, labels, and padding data.\n",
    "    \"\"\"\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    return self.prepare_serialized_examples(serialized_example,\n",
    "        max_quantized_value, min_quantized_value)\n",
    "\n",
    "  def prepare_serialized_examples(self, serialized_example,\n",
    "      max_quantized_value=2, min_quantized_value=-2):\n",
    "\n",
    "    contexts, features = tf.parse_single_sequence_example(\n",
    "        serialized_example,\n",
    "        context_features={\"video_id\": tf.FixedLenFeature(\n",
    "            [], tf.string),\n",
    "                          \"labels\": tf.VarLenFeature(tf.int64)},\n",
    "        sequence_features={\n",
    "            feature_name : tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "            for feature_name in self.feature_names\n",
    "        })\n",
    "\n",
    "    # read ground truth labels\n",
    "    labels = (tf.cast(\n",
    "        tf.sparse_to_dense(contexts[\"labels\"].values, (self.num_classes,), 1,\n",
    "            validate_indices=False),\n",
    "        tf.bool))\n",
    "\n",
    "    # loads (potentially) different types of features and concatenates them\n",
    "    num_features = len(self.feature_names)\n",
    "    assert num_features > 0, \"No feature selected: feature_names is empty!\"\n",
    "\n",
    "    assert len(self.feature_names) == len(self.feature_sizes), \\\n",
    "    \"length of feature_names (={}) != length of feature_sizes (={})\".format( \\\n",
    "    len(self.feature_names), len(self.feature_sizes))\n",
    "\n",
    "    num_frames = -1  # the number of frames in the video\n",
    "    feature_matrices = [None] * num_features  # an array of different features\n",
    "    for feature_index in range(num_features):\n",
    "      feature_matrix, num_frames_in_this_feature = self.get_video_matrix(\n",
    "          features[self.feature_names[feature_index]],\n",
    "          self.feature_sizes[feature_index],\n",
    "          self.max_frames,\n",
    "          max_quantized_value,\n",
    "          min_quantized_value)\n",
    "      if num_frames == -1:\n",
    "        num_frames = num_frames_in_this_feature\n",
    "      else:\n",
    "        tf.assert_equal(num_frames, num_frames_in_this_feature)\n",
    "\n",
    "      feature_matrices[feature_index] = feature_matrix\n",
    "\n",
    "    # cap the number of frames at self.max_frames\n",
    "    num_frames = tf.minimum(num_frames, self.max_frames)\n",
    "\n",
    "    # concatenate different features\n",
    "    video_matrix = tf.concat(feature_matrices, 1)\n",
    "\n",
    "    # convert to batch format.\n",
    "    # TODO: Do proper batch reads to remove the IO bottleneck.\n",
    "    batch_video_ids = tf.expand_dims(contexts[\"video_id\"], 0)\n",
    "    batch_video_matrix = tf.expand_dims(video_matrix, 0)\n",
    "    batch_labels = tf.expand_dims(labels, 0)\n",
    "    batch_frames = tf.expand_dims(num_frames, 0)\n",
    "\n",
    "    return batch_video_ids, batch_video_matrix, batch_labels, batch_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TAmjBdFtv6m1",
    "outputId": "714fda79-a05c-4623-aba9-75636d565a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yvradsmi/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "tITmc0TYwI9D",
    "outputId": "dffcddf1-9112-405e-8be2-c06885ada7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'models' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Uzhhs7P5w6av",
    "outputId": "4d363dc3-14b9-42c8-cdaa-5774eefaf8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yvradsmi/notebooks/models/research/audioset\n"
     ]
    }
   ],
   "source": [
    "cd models/research/audioset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chmod -R 777 audioset_v1_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmUClFszxQsQ"
   },
   "outputs": [],
   "source": [
    "rm vggish_inference_demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jJnvTT6mxZEb",
    "outputId": "b129a3f1-aa13-41aa-b924-443bd1b67be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing vggish_inference_demo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile vggish_inference_demo.py\n",
    "\n",
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "r\"\"\"A simple demonstration of running VGGish in inference mode.\n",
    "\n",
    "This is intended as a toy example that demonstrates how the various building\n",
    "blocks (feature extraction, model definition and loading, postprocessing) work\n",
    "together in an inference context.\n",
    "\n",
    "A WAV file (assumed to contain signed 16-bit PCM samples) is read in, converted\n",
    "into log mel spectrogram examples, fed into VGGish, the raw embedding output is\n",
    "whitened and quantized, and the postprocessed embeddings are optionally written\n",
    "in a SequenceExample to a TFRecord file (using the same format as the embedding\n",
    "features released in AudioSet).\n",
    "\n",
    "Usage:\n",
    "  # Run a WAV file through the model and print the embeddings. The model\n",
    "  # checkpoint is loaded from vggish_model.ckpt and the PCA parameters are\n",
    "  # loaded from vggish_pca_params.npz in the current directory.\n",
    "  $ python vggish_inference_demo.py --wav_file /path/to/a/wav/file\n",
    "\n",
    "  # Run a WAV file through the model and also write the embeddings to\n",
    "  # a TFRecord file. The model checkpoint and PCA parameters are explicitly\n",
    "  # passed in as well.\n",
    "  $ python vggish_inference_demo.py --wav_file /path/to/a/wav/file \\\n",
    "                                    --tfrecord_file /path/to/tfrecord/file \\\n",
    "                                    --checkpoint /path/to/model/checkpoint \\\n",
    "                                    --pca_params /path/to/pca/params\n",
    "\n",
    "  # Run a built-in input (a sine wav) through the model and print the\n",
    "  # embeddings. Associated model files are read from the current directory.\n",
    "  $ python vggish_inference_demo.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_slim\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'wav_file', None,\n",
    "    'Path to a wav file. Should contain signed 16-bit PCM samples. '\n",
    "    'If none is provided, a synthetic sound is used.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'checkpoint', 'vggish_model.ckpt',\n",
    "    'Path to the VGGish checkpoint file.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'pca_params', 'vggish_pca_params.npz',\n",
    "    'Path to the VGGish PCA parameters file.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'tfrecord_file', None,\n",
    "    'Path to a TFRecord file where embeddings will be written.')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    # In this simple example, we run the examples from a single audio file through\n",
    "    # the model. If none is provided, we generate a synthetic input.\n",
    "    if FLAGS.wav_file:\n",
    "        wav_file = FLAGS.wav_file\n",
    "    else:\n",
    "        # Write a WAV of a sine wav into an in-memory file object.\n",
    "        num_secs = 5\n",
    "        freq = 1000\n",
    "        sr = 44100\n",
    "        t = np.linspace(0, num_secs, int(num_secs * sr))\n",
    "        x = np.sin(2 * np.pi * freq * t)\n",
    "        # Convert to signed 16-bit samples.\n",
    "        samples = np.clip(x * 32768, -32768, 32767).astype(np.int16)\n",
    "        wav_file = six.BytesIO()\n",
    "        wavfile.write(wav_file, sr, samples)\n",
    "        wav_file.seek(0)\n",
    "    examples_batch = vggish_input.wavfile_to_examples(wav_file)\n",
    "    print(examples_batch)\n",
    "\n",
    "    # Prepare a postprocessor to munge the model embeddings.\n",
    "    pproc = vggish_postprocess.Postprocessor(FLAGS.pca_params)\n",
    "\n",
    "    # If needed, prepare a record writer to store the postprocessed embeddings.\n",
    "    writer = tf.python_io.TFRecordWriter(\n",
    "        FLAGS.tfrecord_file) if FLAGS.tfrecord_file else None\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        # Define the model in inference mode, load the checkpoint, and\n",
    "        # locate input and output tensors.\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, FLAGS.checkpoint)\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "        # Run inference and postprocessing.\n",
    "        [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                     feed_dict={features_tensor: examples_batch})\n",
    "        print(embedding_batch)\n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "        print(postprocessed_batch)\n",
    "\n",
    "        # Write the postprocessed embeddings as a SequenceExample, in a similar\n",
    "        # format as the features released in AudioSet. Each row of the batch of\n",
    "        # embeddings corresponds to roughly a second of audio (96 10ms frames), and\n",
    "        # the rows are written as a sequence of bytes-valued features, where each\n",
    "        # feature value contains the 128 bytes of the whitened quantized embedding.\n",
    "        seq_example = tf.train.SequenceExample(\n",
    "            context=tf.train.Features(feature={\n",
    "                'video_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[wav_file.encode()]))\n",
    "            }),\n",
    "            feature_lists=tf.train.FeatureLists(\n",
    "                feature_list={\n",
    "                    vggish_params.AUDIO_EMBEDDING_FEATURE_NAME:\n",
    "                        tf.train.FeatureList(\n",
    "                            feature=[\n",
    "                                tf.train.Feature(\n",
    "                                    bytes_list=tf.train.BytesList(\n",
    "                                        value=[embedding.tobytes()]))\n",
    "                                for embedding in postprocessed_batch\n",
    "                            ]\n",
    "                        )\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        print(seq_example)\n",
    "        if writer:\n",
    "            writer.write(seq_example.SerializeToString())\n",
    "\n",
    "    if writer:\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "dxzl-0pnxuEG",
    "outputId": "c2f9162e-fcd6-4485-937e-7d81bac77d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yvradsmi/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd /home/yvradsmi/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M-FQFRGwxvno",
    "outputId": "4e39a282-d1fa-4926-c20a-f1fc3b6fb355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42maudioset_v1_embeddings\u001b[0m/\r\n",
      "\u001b[34;42mazureml\u001b[0m/\r\n",
      "\u001b[34;42mBatchAI\u001b[0m/\r\n",
      "\u001b[34;42mcaffe2\u001b[0m/\r\n",
      "\u001b[34;42mcatboost\u001b[0m/\r\n",
      "\u001b[34;42mChainer\u001b[0m/\r\n",
      "\u001b[34;42mCNTK\u001b[0m/\r\n",
      "\u001b[01;32mcuda-repo-ubuntu1604_8.0.44-1_amd64.deb\u001b[0m*\r\n",
      "\u001b[34;42mdeep_water\u001b[0m/\r\n",
      "\u001b[01;32mDocumentDBSample.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mfeatures.tar.gz\u001b[0m*\r\n",
      "\u001b[34;42mh2o\u001b[0m/\r\n",
      "\u001b[01;32mIDEAR.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroduction to Azure ML R notebooks.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroduction to Microsoft R Operationalization.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroToJupyterPython.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroTutorialinMicrosoftR.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIntroTutorialinR.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mIrisClassifierPyMLWebService.ipynb\u001b[0m*\r\n",
      "\u001b[34;42mjulia\u001b[0m/\r\n",
      "\u001b[01;32mLoadDataIntoDW.ipynb\u001b[0m*\r\n",
      "\u001b[34;42mMMLSpark\u001b[0m/\r\n",
      "\u001b[34;42mmodel_new\u001b[0m/\r\n",
      "\u001b[34;42mmodels\u001b[0m/\r\n",
      "\u001b[34;42mmxnet\u001b[0m/\r\n",
      "\u001b[01;32mpassword\u001b[0m*\r\n",
      "\u001b[34;42mpytorch\u001b[0m/\r\n",
      "\u001b[01;32mreaders.py\u001b[0m*\r\n",
      "\u001b[34;42mSparkML\u001b[0m/\r\n",
      "\u001b[01;32mSQLDW_Explorations.ipynb\u001b[0m*\r\n",
      "\u001b[34;42mtensorflow\u001b[0m/\r\n",
      "\u001b[01;32mVGGish_Audioset_&_Audio_embedding_Tutorial.ipynb\u001b[0m*\r\n",
      "\u001b[01;32mvggish_model.ckpt\u001b[0m*\r\n",
      "\u001b[01;32mvggish_pca_params.npz\u001b[0m*\r\n",
      "\u001b[34;42myoutube-8m\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1697
    },
    "colab_type": "code",
    "id": "Ukp5n4xqx4PX",
    "outputId": "a13079e3-d1d3-4176-e04e-96845620f277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:/job:master/task:0: Tensorflow version: 1.11.0.\n",
      "WARNING:tensorflow:From /home/yvradsmi/notebooks/youtube-8m/frame_level_models.py:221: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "INFO:tensorflow:/job:master/task:0: Removing existing train directory.\n",
      "INFO:tensorflow:/job:master/task:0: Flag 'start_new_model' is set. Building a new model.\n",
      "2018-09-30 23:34:32.067971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-09-30 23:34:32.183779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 6de9:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2018-09-30 23:34:32.183826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2018-09-30 23:34:32.461848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-09-30 23:34:32.461926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2018-09-30 23:34:32.461951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2018-09-30 23:34:32.462222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 6de9:00:00.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Using the following GPUs to train: ['/device:GPU:0']\n",
      "INFO:tensorflow:Using batch size of 1024 for training.\n",
      "INFO:tensorflow:Number of training files: 4070.\n",
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From youtube-8m/train.py:436: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:/job:master/task:0: Starting managed session.\n",
      "2018-09-30 23:34:34.116736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2018-09-30 23:34:34.116796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-09-30 23:34:34.116816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2018-09-30 23:34:34.116831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2018-09-30 23:34:34.116961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 6de9:00:00.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path model_new/dir/model.ckpt\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:/job:master/task:0: Entering training loop.\n",
      "INFO:tensorflow:model_new/dir/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:training step 1 | Loss: 215.32 Examples/sec: 347.87\n",
      "INFO:tensorflow:training step 2 | Loss: 214.16 Examples/sec: 1347.00\n",
      "INFO:tensorflow:training step 3 | Loss: 202.41 Examples/sec: 1353.48\n",
      "INFO:tensorflow:training step 4 | Loss: 136.63 Examples/sec: 1337.90\n",
      "INFO:tensorflow:training step 5 | Loss: 37.28 Examples/sec: 1354.75\n",
      "INFO:tensorflow:training step 6 | Loss: 23.32 Examples/sec: 1337.14\n",
      "INFO:tensorflow:training step 7 | Loss: 20.93 Examples/sec: 1366.20\n",
      "INFO:tensorflow:training step 8 | Loss: 21.39 Examples/sec: 1328.33\n",
      "INFO:tensorflow:training step 9 | Loss: 19.95 Examples/sec: 1351.07\n",
      "INFO:tensorflow:training step 10 | Loss: 17.07 Examples/sec: 1338.38 | Hit@1: 0.30 PERR: 0.24 GAP: 0.11\n",
      "INFO:tensorflow:model_new/dir/model.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/job:master/task:0: Exporting the model at step 10 to model_new/dir/export/step_10.\n",
      "2018-09-30 23:34:46.023725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2018-09-30 23:34:46.023773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-09-30 23:34:46.023781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2018-09-30 23:34:46.023787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2018-09-30 23:34:46.023910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 6de9:00:00.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Restoring parameters from model_new/dir/model.ckpt-10\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: model_new/dir/export/step_10/saved_model.pb\n",
      "INFO:tensorflow:training step 11 | Loss: 15.47 Examples/sec: 1679.41\n",
      "INFO:tensorflow:training step 12 | Loss: 14.88 Examples/sec: 1668.51\n",
      "INFO:tensorflow:training step 13 | Loss: 14.22 Examples/sec: 1340.11\n",
      "INFO:tensorflow:training step 14 | Loss: 13.42 Examples/sec: 1352.10\n",
      "INFO:tensorflow:training step 15 | Loss: 13.11 Examples/sec: 1354.25\n",
      "INFO:tensorflow:training step 16 | Loss: 13.65 Examples/sec: 1337.20\n",
      "INFO:tensorflow:training step 17 | Loss: 13.26 Examples/sec: 1351.36\n",
      "INFO:tensorflow:training step 18 | Loss: 13.30 Examples/sec: 1338.25\n",
      "INFO:tensorflow:training step 19 | Loss: 13.22 Examples/sec: 1335.91\n",
      "INFO:tensorflow:training step 20 | Loss: 13.84 Examples/sec: 1334.51 | Hit@1: 0.25 PERR: 0.21 GAP: 0.07\n",
      "INFO:tensorflow:training step 21 | Loss: 13.22 Examples/sec: 1403.01\n",
      "INFO:tensorflow:training step 22 | Loss: 13.29 Examples/sec: 1353.73\n",
      "INFO:tensorflow:training step 23 | Loss: 13.63 Examples/sec: 1337.46\n",
      "INFO:tensorflow:training step 24 | Loss: 13.55 Examples/sec: 1339.25\n",
      "INFO:tensorflow:training step 25 | Loss: 13.41 Examples/sec: 1354.79\n",
      "INFO:tensorflow:training step 26 | Loss: 13.61 Examples/sec: 1355.71\n",
      "INFO:tensorflow:training step 27 | Loss: 13.35 Examples/sec: 1349.96\n",
      "INFO:tensorflow:training step 28 | Loss: 13.46 Examples/sec: 1255.77\n",
      "INFO:tensorflow:training step 29 | Loss: 13.19 Examples/sec: 1266.17\n",
      "INFO:tensorflow:training step 30 | Loss: 13.56 Examples/sec: 1305.41 | Hit@1: 0.27 PERR: 0.20 GAP: 0.09\n",
      "INFO:tensorflow:training step 31 | Loss: 13.26 Examples/sec: 1422.36\n",
      "INFO:tensorflow:training step 32 | Loss: 13.26 Examples/sec: 1348.23\n",
      "INFO:tensorflow:training step 33 | Loss: 13.39 Examples/sec: 1332.34\n",
      "INFO:tensorflow:training step 34 | Loss: 13.07 Examples/sec: 1340.19\n",
      "INFO:tensorflow:training step 35 | Loss: 13.03 Examples/sec: 1316.32\n",
      "INFO:tensorflow:training step 36 | Loss: 13.21 Examples/sec: 1361.49\n",
      "INFO:tensorflow:training step 37 | Loss: 13.03 Examples/sec: 1349.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training step 38 | Loss: 13.01 Examples/sec: 1323.14\n",
      "INFO:tensorflow:training step 39 | Loss: 13.46 Examples/sec: 1338.75\n",
      "INFO:tensorflow:training step 40 | Loss: 13.51 Examples/sec: 1276.57 | Hit@1: 0.27 PERR: 0.21 GAP: 0.10\n",
      "INFO:tensorflow:training step 41 | Loss: 13.42 Examples/sec: 1494.18\n",
      "INFO:tensorflow:training step 42 | Loss: 12.82 Examples/sec: 1337.42\n",
      "INFO:tensorflow:training step 43 | Loss: 12.81 Examples/sec: 1333.97\n",
      "INFO:tensorflow:training step 44 | Loss: 13.38 Examples/sec: 1336.68\n",
      "INFO:tensorflow:training step 45 | Loss: 13.25 Examples/sec: 1357.42\n",
      "INFO:tensorflow:training step 46 | Loss: 13.13 Examples/sec: 1338.30\n",
      "INFO:tensorflow:training step 47 | Loss: 13.38 Examples/sec: 1336.42\n",
      "INFO:tensorflow:training step 48 | Loss: 13.35 Examples/sec: 1336.97\n",
      "INFO:tensorflow:training step 49 | Loss: 13.55 Examples/sec: 1318.87\n",
      "INFO:tensorflow:training step 50 | Loss: 13.15 Examples/sec: 1338.41 | Hit@1: 0.29 PERR: 0.22 GAP: 0.11\n",
      "INFO:tensorflow:training step 51 | Loss: 13.26 Examples/sec: 1487.68\n",
      "INFO:tensorflow:training step 52 | Loss: 13.06 Examples/sec: 1323.36\n",
      "INFO:tensorflow:training step 53 | Loss: 13.22 Examples/sec: 1295.35\n",
      "INFO:tensorflow:training step 54 | Loss: 13.31 Examples/sec: 1361.46\n",
      "INFO:tensorflow:training step 55 | Loss: 13.47 Examples/sec: 1309.20\n",
      "INFO:tensorflow:training step 56 | Loss: 13.20 Examples/sec: 1366.43\n",
      "INFO:tensorflow:training step 57 | Loss: 13.06 Examples/sec: 1302.27\n",
      "INFO:tensorflow:training step 58 | Loss: 13.19 Examples/sec: 1355.06\n",
      "INFO:tensorflow:training step 59 | Loss: 12.89 Examples/sec: 1289.37\n",
      "INFO:tensorflow:training step 60 | Loss: 13.19 Examples/sec: 1304.55 | Hit@1: 0.28 PERR: 0.22 GAP: 0.11\n",
      "INFO:tensorflow:training step 61 | Loss: 13.55 Examples/sec: 1440.81\n",
      "INFO:tensorflow:training step 62 | Loss: 13.33 Examples/sec: 1326.49\n",
      "INFO:tensorflow:training step 63 | Loss: 13.13 Examples/sec: 1327.78\n",
      "INFO:tensorflow:training step 64 | Loss: 13.29 Examples/sec: 1342.97\n",
      "INFO:tensorflow:training step 65 | Loss: 13.21 Examples/sec: 1305.52\n",
      "INFO:tensorflow:training step 66 | Loss: 13.45 Examples/sec: 1347.13\n",
      "INFO:tensorflow:training step 67 | Loss: 13.08 Examples/sec: 1333.03\n",
      "INFO:tensorflow:training step 68 | Loss: 13.02 Examples/sec: 1333.71\n",
      "INFO:tensorflow:training step 69 | Loss: 13.35 Examples/sec: 1322.80\n",
      "INFO:tensorflow:training step 70 | Loss: 13.27 Examples/sec: 1295.38 | Hit@1: 0.29 PERR: 0.22 GAP: 0.11\n",
      "INFO:tensorflow:training step 71 | Loss: 12.99 Examples/sec: 1422.45\n",
      "INFO:tensorflow:training step 72 | Loss: 13.49 Examples/sec: 1300.18\n",
      "INFO:tensorflow:training step 73 | Loss: 13.07 Examples/sec: 1355.27\n",
      "INFO:tensorflow:training step 74 | Loss: 13.32 Examples/sec: 1353.07\n",
      "INFO:tensorflow:training step 75 | Loss: 12.77 Examples/sec: 1327.55\n",
      "INFO:tensorflow:training step 76 | Loss: 13.21 Examples/sec: 1323.01\n",
      "INFO:tensorflow:training step 77 | Loss: 13.32 Examples/sec: 1343.32\n",
      "INFO:tensorflow:training step 78 | Loss: 12.88 Examples/sec: 1286.09\n",
      "INFO:tensorflow:training step 79 | Loss: 13.16 Examples/sec: 1320.03\n",
      "INFO:tensorflow:training step 80 | Loss: 12.90 Examples/sec: 1356.01 | Hit@1: 0.27 PERR: 0.22 GAP: 0.11\n",
      "INFO:tensorflow:training step 81 | Loss: 13.51 Examples/sec: 1441.93\n",
      "INFO:tensorflow:training step 82 | Loss: 13.30 Examples/sec: 1345.56\n",
      "INFO:tensorflow:training step 83 | Loss: 13.20 Examples/sec: 1337.18\n",
      "INFO:tensorflow:training step 84 | Loss: 13.27 Examples/sec: 1318.45\n",
      "INFO:tensorflow:training step 85 | Loss: 13.27 Examples/sec: 1351.30\n",
      "INFO:tensorflow:training step 86 | Loss: 13.10 Examples/sec: 1338.72\n",
      "INFO:tensorflow:training step 87 | Loss: 13.49 Examples/sec: 1336.53\n",
      "INFO:tensorflow:training step 88 | Loss: 12.86 Examples/sec: 1336.98\n",
      "INFO:tensorflow:training step 89 | Loss: 13.49 Examples/sec: 1300.74\n",
      "INFO:tensorflow:training step 90 | Loss: 13.00 Examples/sec: 1318.45 | Hit@1: 0.28 PERR: 0.23 GAP: 0.12\n",
      "INFO:tensorflow:training step 91 | Loss: 13.53 Examples/sec: 1441.31\n",
      "INFO:tensorflow:training step 92 | Loss: 13.24 Examples/sec: 1335.83\n",
      "INFO:tensorflow:training step 93 | Loss: 13.09 Examples/sec: 1337.66\n",
      "INFO:tensorflow:training step 94 | Loss: 12.99 Examples/sec: 1337.97\n",
      "INFO:tensorflow:training step 95 | Loss: 12.95 Examples/sec: 1333.35\n",
      "INFO:tensorflow:training step 96 | Loss: 13.34 Examples/sec: 1328.48\n",
      "INFO:tensorflow:training step 97 | Loss: 13.28 Examples/sec: 1273.94\n",
      "INFO:tensorflow:training step 98 | Loss: 13.08 Examples/sec: 1358.04\n",
      "INFO:tensorflow:training step 99 | Loss: 13.01 Examples/sec: 1337.22\n",
      "INFO:tensorflow:training step 100 | Loss: 13.03 Examples/sec: 1338.94 | Hit@1: 0.29 PERR: 0.23 GAP: 0.12\n",
      "INFO:tensorflow:training step 101 | Loss: 13.10 Examples/sec: 1464.33\n",
      "INFO:tensorflow:training step 102 | Loss: 12.86 Examples/sec: 1337.19\n",
      "INFO:tensorflow:training step 103 | Loss: 13.64 Examples/sec: 1337.64\n",
      "INFO:tensorflow:training step 104 | Loss: 13.42 Examples/sec: 1333.90\n",
      "INFO:tensorflow:training step 105 | Loss: 13.33 Examples/sec: 1322.03\n",
      "INFO:tensorflow:training step 106 | Loss: 13.02 Examples/sec: 1350.07\n",
      "INFO:tensorflow:training step 107 | Loss: 13.08 Examples/sec: 1602.74\n",
      "INFO:tensorflow:training step 108 | Loss: 13.35 Examples/sec: 1040.86\n",
      "INFO:tensorflow:/job:master/task:0: Done training -- epoch limit reached.\n",
      "INFO:tensorflow:/job:master/task:0: Exited training loop.\n"
     ]
    }
   ],
   "source": [
    "!python youtube-8m/train.py --frame_features --model=LstmModel --feature_names=audio_embedding --feature_sizes=128 --train_data_pattern=audioset_v1_embeddings/bal_train/*.tfrecord --train_dir model_new/dir --start_new_model --base_learning_rate=0.001 --num_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal_train  eval  unbal_train\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/yvradsmi/notebooks/audioset_v1_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "tensorflow version: 1.11.0\n",
      "INFO:tensorflow:Using batch size of 1024 for evaluation.\n",
      "INFO:tensorflow:number of evaluation files: 4062\n",
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/yvradsmi/notebooks/youtube-8m/frame_level_models.py:221: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "INFO:tensorflow:built evaluation graph\n",
      "2018-09-30 23:44:08.314307: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-09-30 23:44:08.434972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 6de9:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2018-09-30 23:44:08.435032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2018-09-30 23:44:08.723418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-09-30 23:44:08.723486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2018-09-30 23:44:08.723508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2018-09-30 23:44:08.723772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 6de9:00:00.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Loading checkpoint for eval: model_new/dir/model.ckpt-10\n",
      "INFO:tensorflow:Restoring parameters from model_new/dir/model.ckpt-10\n",
      "INFO:tensorflow:enter eval_once loop global_step_val = 10. \n",
      "INFO:tensorflow:examples_processed: 1024 | global_step 10 | Batch Hit@1: 0.271 | Batch PERR: 0.211 | Batch Loss: 15.799 | Examples_per_sec: 763.625\n",
      "INFO:tensorflow:examples_processed: 2048 | global_step 10 | Batch Hit@1: 0.280 | Batch PERR: 0.204 | Batch Loss: 15.818 | Examples_per_sec: 1476.271\n",
      "INFO:tensorflow:examples_processed: 3072 | global_step 10 | Batch Hit@1: 0.305 | Batch PERR: 0.217 | Batch Loss: 16.180 | Examples_per_sec: 1484.946\n",
      "INFO:tensorflow:examples_processed: 4096 | global_step 10 | Batch Hit@1: 0.282 | Batch PERR: 0.208 | Batch Loss: 16.040 | Examples_per_sec: 1539.042\n",
      "INFO:tensorflow:examples_processed: 5120 | global_step 10 | Batch Hit@1: 0.289 | Batch PERR: 0.218 | Batch Loss: 16.528 | Examples_per_sec: 1513.874\n",
      "INFO:tensorflow:examples_processed: 6144 | global_step 10 | Batch Hit@1: 0.265 | Batch PERR: 0.204 | Batch Loss: 16.379 | Examples_per_sec: 1523.618\n",
      "INFO:tensorflow:examples_processed: 7168 | global_step 10 | Batch Hit@1: 0.285 | Batch PERR: 0.218 | Batch Loss: 16.494 | Examples_per_sec: 1540.325\n",
      "INFO:tensorflow:examples_processed: 8192 | global_step 10 | Batch Hit@1: 0.269 | Batch PERR: 0.210 | Batch Loss: 16.219 | Examples_per_sec: 1507.413\n",
      "INFO:tensorflow:examples_processed: 9216 | global_step 10 | Batch Hit@1: 0.272 | Batch PERR: 0.210 | Batch Loss: 15.855 | Examples_per_sec: 1412.830\n",
      "INFO:tensorflow:examples_processed: 10240 | global_step 10 | Batch Hit@1: 0.285 | Batch PERR: 0.207 | Batch Loss: 15.913 | Examples_per_sec: 1378.978\n",
      "INFO:tensorflow:examples_processed: 11264 | global_step 10 | Batch Hit@1: 0.271 | Batch PERR: 0.210 | Batch Loss: 15.932 | Examples_per_sec: 1461.652\n",
      "INFO:tensorflow:examples_processed: 12288 | global_step 10 | Batch Hit@1: 0.271 | Batch PERR: 0.214 | Batch Loss: 15.881 | Examples_per_sec: 1428.142\n",
      "INFO:tensorflow:examples_processed: 13312 | global_step 10 | Batch Hit@1: 0.254 | Batch PERR: 0.211 | Batch Loss: 15.926 | Examples_per_sec: 1520.088\n",
      "INFO:tensorflow:examples_processed: 14336 | global_step 10 | Batch Hit@1: 0.285 | Batch PERR: 0.209 | Batch Loss: 16.247 | Examples_per_sec: 1518.418\n",
      "INFO:tensorflow:examples_processed: 15360 | global_step 10 | Batch Hit@1: 0.262 | Batch PERR: 0.206 | Batch Loss: 16.179 | Examples_per_sec: 1529.269\n",
      "INFO:tensorflow:examples_processed: 16384 | global_step 10 | Batch Hit@1: 0.285 | Batch PERR: 0.220 | Batch Loss: 15.767 | Examples_per_sec: 1517.175\n",
      "INFO:tensorflow:examples_processed: 17408 | global_step 10 | Batch Hit@1: 0.271 | Batch PERR: 0.215 | Batch Loss: 15.923 | Examples_per_sec: 1521.644\n",
      "INFO:tensorflow:examples_processed: 18432 | global_step 10 | Batch Hit@1: 0.309 | Batch PERR: 0.213 | Batch Loss: 16.193 | Examples_per_sec: 1522.160\n",
      "INFO:tensorflow:examples_processed: 19456 | global_step 10 | Batch Hit@1: 0.283 | Batch PERR: 0.212 | Batch Loss: 16.198 | Examples_per_sec: 1512.962\n",
      "INFO:tensorflow:examples_processed: 20371 | global_step 10 | Batch Hit@1: 0.297 | Batch PERR: 0.211 | Batch Loss: 16.288 | Examples_per_sec: 1525.914\n",
      "INFO:tensorflow:Done with batched inference. Now calculating global performance metrics.\n",
      "INFO:tensorflow:epoch/eval number 10 | Avg_Hit@1: 0.280 | Avg_PERR: 0.211 | MAP: 0.002 | GAP: 0.090 | Avg_Loss: 16.086829\n"
     ]
    }
   ],
   "source": [
    "!python youtube-8m/eval.py --eval_data_pattern=audioset_v1_embeddings/eval/*.tfrecord --train_dir model_new/dir --run_once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-09-30 23:48:16.204317: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-09-30 23:48:16.316354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 6de9:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2018-09-30 23:48:16.316399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2018-09-30 23:48:16.596182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-09-30 23:48:16.596244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2018-09-30 23:48:16.596264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2018-09-30 23:48:16.596525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 6de9:00:00.0, compute capability: 3.7)\n",
      "INFO:tensorflow:number of input files: 64\n",
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:loading meta-graph: model_new/dir/inference_model.meta\n",
      "INFO:tensorflow:restoring variables from model_new/dir/inference_model\n",
      "INFO:tensorflow:Restoring parameters from model_new/dir/inference_model\n",
      "WARNING:tensorflow:From youtube-8m/inference.py:161: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:num examples processed: 320 elapsed seconds: 1.22\n",
      "INFO:tensorflow:Done with inference. The output file was written to Bal_SamplePredictions.csv\n"
     ]
    }
   ],
   "source": [
    "!python youtube-8m/inference.py --output_file Bal_SamplePredictions.csv --input_data_pattern=audioset_v1_embeddings/bal_train/a*.tfrecord --train_dir model_new/dir --top_k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoId,LabelConfidencePairs\r\n",
      "aL2jpZfUGF0,137 0.574492 0 0.483146 300 0.218803\r\n",
      "aLnpHdhIqWE,137 0.573679 0 0.470482 300 0.207713\r\n",
      "aL6wtF-CqmA,137 0.574365 0 0.483363 300 0.218834\r\n",
      "aLiocIeE_A8,137 0.574256 0 0.483674 300 0.219061\r\n",
      "aLShWsDr7oQ,137 0.574368 0 0.483129 300 0.218811\r\n",
      "aLnBwjLUZao,137 0.574418 0 0.48309 300 0.218628\r\n",
      "aL6ij87TUA8,137 0.574551 0 0.482986 300 0.218652\r\n",
      "aLHxMaT3uYg,137 0.574506 0 0.483235 300 0.218777\r\n",
      "aA0bk6Pnh7A,137 0.574131 0 0.484086 300 0.219288\r\n",
      "aAU9NKbaGy4,137 0.57447 0 0.482616 300 0.218318\r\n",
      "aA1Z3eeFYm0,137 0.575466 0 0.478522 300 0.215218\r\n",
      "aADExWV1bsM,137 0.574436 0 0.483521 300 0.218996\r\n",
      "aAJuPyUvHn8,137 0.574185 0 0.48379 300 0.219207\r\n",
      "aAtMoktAtVs,137 0.574251 0 0.483607 300 0.218909\r\n",
      "amvaj68CwfM,137 0.5745 0 0.482738 300 0.218326\r\n",
      "ammKLbpCiwU,137 0.574252 0 0.483638 300 0.219043\r\n",
      "au3EcuW7nHw,137 0.57476 0 0.481196 300 0.217086\r\n",
      "a4D3uaGlkwg,137 0.574334 0 0.483547 300 0.219042\r\n",
      "a4SXfQjkkbk,137 0.574207 0 0.483801 300 0.21909\r\n",
      "a4-FJctXu38,137 0.574079 0 0.48415 300 0.219321\r\n",
      "a4Ay4RfMm1U,137 0.574461 0 0.483192 300 0.218638\r\n",
      "a4nkA0NL4Hw,137 0.574376 0 0.48172 300 0.217161\r\n",
      "a4L7FzFE1G4,137 0.574132 0 0.483648 300 0.219024\r\n",
      "aNrBZqiwwgk,137 0.574561 0 0.482717 300 0.218441\r\n",
      "aN9EnF2eQhw,137 0.574285 0 0.483527 300 0.218849\r\n",
      "aNKJs1Y59RU,137 0.574519 0 0.482467 300 0.218178\r\n",
      "aNHlk9YSaD4,137 0.574404 0 0.482837 300 0.218491\r\n",
      "aNjtfIoVzas,137 0.574513 0 0.482888 300 0.218452\r\n",
      "aNguMUPxN_Y,137 0.57486 0 0.480751 300 0.21665\r\n",
      "aNVuzhaxH2Y,137 0.574188 0 0.483819 300 0.219118\r\n",
      "aNJEh3_Vmps,137 0.574369 0 0.48303 300 0.218581\r\n",
      "aq7axBA11pE,137 0.574484 0 0.482649 300 0.218381\r\n",
      "aqSEXhv5Cqg,137 0.57462 0 0.482199 300 0.217979\r\n",
      "aqqbxRvPb2I,137 0.574355 0 0.483357 300 0.218874\r\n",
      "aqOSowdUE8Y,137 0.575018 0 0.479583 300 0.216047\r\n",
      "aqpZ84SYkIs,137 0.574373 0 0.48355 300 0.218949\r\n",
      "aqozZzRbHVg,137 0.574677 0 0.482715 300 0.218346\r\n",
      "a2i5-eTPWGg,137 0.574242 0 0.483473 300 0.218933\r\n",
      "a2WYcwsDHU0,137 0.574519 0 0.482452 300 0.218104\r\n",
      "a2F0fGm1eWk,137 0.574294 0 0.48317 300 0.21862\r\n",
      "a2YgBv4l_v8,137 0.574335 0 0.483546 300 0.219149\r\n",
      "a2ugthH2Urk,137 0.574522 0 0.482748 300 0.218404\r\n",
      "a28W1fiUd6g,137 0.574283 0 0.48351 300 0.218967\r\n",
      "a2bqZ6PVWM0,137 0.574901 0 0.480948 300 0.216969\r\n",
      "a2dgzb9GDSQ,137 0.574256 0 0.483473 300 0.218816\r\n",
      "a2KbrnPW7aA,137 0.574418 0 0.482439 300 0.217942\r\n",
      "aXxoWLiwdDU,137 0.574444 0 0.482781 300 0.218357\r\n",
      "aXDgw2fLHAA,137 0.574522 0 0.482964 300 0.218525\r\n",
      "aXwyfGdFM64,137 0.574077 0 0.483821 300 0.219056\r\n",
      "aXIQc2RtvfA,137 0.574597 0 0.481881 300 0.217668\r\n",
      "aXnmfM7UBPw,137 0.57445 0 0.482606 300 0.218359\r\n",
      "aXsUHAKbyLs,137 0.574292 0 0.483707 300 0.21912\r\n",
      "aD-nQuNvBEE,137 0.574401 0 0.482924 300 0.218482\r\n",
      "aDlWOvCdNMk,137 0.574781 0 0.481521 300 0.217438\r\n",
      "aD-IMxe1px0,137 0.573697 0 0.469077 300 0.206697\r\n",
      "aDmhcvIIpgY,137 0.574574 0 0.481604 300 0.217254\r\n",
      "aDMsH8STzE8,137 0.574258 0 0.483412 300 0.218987\r\n",
      "aIIEI33EUqI,137 0.574427 0 0.482662 300 0.218319\r\n",
      "aImEmnLVt5o,137 0.574774 0 0.481272 300 0.217129\r\n",
      "aH6XgLo6gBw,137 0.574474 0 0.482625 300 0.218152\r\n",
      "aHxWuDdWjYs,137 0.574233 0 0.483342 300 0.218876\r\n",
      "aH02jriJhNs,137 0.574144 0 0.483399 300 0.218891\r\n",
      "aHZdDmYFZN0,137 0.575541 0 0.477477 300 0.214504\r\n",
      "aHvYVxh-aus,137 0.5742 0 0.483965 300 0.21928\r\n",
      "aHZXc7jUn4o,137 0.574394 0 0.482759 300 0.218363\r\n",
      "a_mdhaQPQ3w,137 0.574082 0 0.484142 300 0.21933\r\n",
      "a_j5TYIcN-s,137 0.574649 0 0.482533 300 0.218306\r\n",
      "a_PIv78M240,137 0.574317 0 0.483605 300 0.218995\r\n",
      "a_t61PhbjdY,137 0.574481 0 0.482907 300 0.218445\r\n",
      "a_r8wKJ8ePw,137 0.574458 0 0.483152 300 0.218803\r\n",
      "a_ToJYT0v9k,137 0.575015 0 0.481105 300 0.217135\r\n",
      "a_La3oXEbTw,137 0.574301 0 0.483033 300 0.218472\r\n",
      "a_J-D388Seo,137 0.57445 0 0.483055 300 0.218545\r\n",
      "aGCuk_G18_I,137 0.57453 0 0.482688 300 0.218398\r\n",
      "aGZKHem0IQk,137 0.574234 0 0.483664 300 0.219115\r\n",
      "aGMdcxeF6Ak,137 0.574935 0 0.480881 300 0.21701\r\n",
      "aGO7JSdb3bc,137 0.574416 0 0.483012 300 0.218571\r\n",
      "aGsIjsja0JQ,137 0.574182 0 0.483957 300 0.219228\r\n",
      "aGMSGAinfQQ,137 0.574215 0 0.483323 300 0.218787\r\n",
      "aURLQXt_6fE,137 0.574469 0 0.482986 300 0.218577\r\n",
      "aUxWi-9eWik,137 0.57404 0 0.483968 300 0.219277\r\n",
      "aUDF9ehodLw,137 0.574366 0 0.483024 300 0.21865\r\n",
      "aUKZbLMFFAc,137 0.574332 0 0.483293 300 0.218795\r\n",
      "ainzK7QuseU,137 0.57441 0 0.483216 300 0.2187\r\n",
      "aWxPsqi_wL4,137 0.574433 0 0.482797 300 0.218466\r\n",
      "aWw_W3DhJEo,137 0.574465 0 0.483159 300 0.218712\r\n",
      "aWvNO-rCLNQ,137 0.574361 0 0.483313 300 0.2188\r\n",
      "aCTm1TcL7z8,137 0.574593 0 0.482865 300 0.218545\r\n",
      "aC3IBcRNyro,137 0.574949 0 0.481195 300 0.217309\r\n",
      "aCG7Y_0Cs28,137 0.574318 0 0.483687 300 0.219096\r\n",
      "aCjaEKst558,137 0.574097 0 0.483885 300 0.219129\r\n",
      "apkXWaneA9E,137 0.574456 0 0.48231 300 0.218023\r\n",
      "apA0IY_5-2g,137 0.575113 0 0.479602 300 0.215918\r\n",
      "apwQu55-5OI,137 0.574728 0 0.481823 300 0.217706\r\n",
      "apiwldD6mRo,137 0.574232 0 0.48366 300 0.218951\r\n",
      "apWwq55i-Kw,137 0.57452 0 0.482482 300 0.218205\r\n",
      "apAFcRFutFo,137 0.574149 0 0.483649 300 0.219041\r\n",
      "apaH7oczgoA,137 0.574233 0 0.483169 300 0.218662\r\n",
      "akfDjE4v3PI,137 0.575029 0 0.479215 300 0.21567\r\n",
      "ak9HTVq5mBw,137 0.574403 0 0.483353 300 0.218807\r\n",
      "akcF62mJvmQ,137 0.574223 0 0.482727 300 0.218151\r\n",
      "akn4pGhdxo4,137 0.574912 0 0.480154 300 0.216299\r\n",
      "aSWNiPRbZ6Q,137 0.574347 0 0.483035 300 0.218704\r\n",
      "aSNvKefxs4c,137 0.574038 0 0.483841 300 0.219113\r\n",
      "aSzsxNbMl3Q,137 0.575352 0 0.477063 300 0.214027\r\n",
      "aSwoZVWDd1w,137 0.574447 0 0.482724 300 0.218331\r\n",
      "aSeFfdcrpSs,137 0.574364 0 0.483347 300 0.218738\r\n",
      "aSCH3Noht9A,137 0.57457 0 0.48197 300 0.217835\r\n",
      "aScgOtm4BDM,137 0.574545 0 0.482448 300 0.218123\r\n",
      "aSP7DDY1lz4,137 0.574403 0 0.483449 300 0.218834\r\n",
      "aSyRV5j2zV4,137 0.574761 0 0.481376 300 0.217306\r\n",
      "afkfqCzgSzc,137 0.574314 0 0.483154 300 0.2187\r\n",
      "afqE252eplM,137 0.574191 0 0.483321 300 0.218797\r\n",
      "afGrjbK2XIY,137 0.57501 0 0.480631 300 0.216692\r\n",
      "ae9kRlD93fI,137 0.574321 0 0.483175 300 0.218655\r\n",
      "aenz9onGI3s,137 0.574295 0 0.483363 300 0.218921\r\n",
      "aeiOyhQ8PXs,137 0.57432 0 0.483065 300 0.218515\r\n",
      "aeujZtBvMFY,137 0.575168 0 0.479682 300 0.216072\r\n",
      "ae3cG6QAos0,137 0.574389 0 0.482917 300 0.218296\r\n",
      "aek3GoFr5MI,137 0.582573 0 0.440846 300 0.191398\r\n",
      "aed5GPVfOy4,137 0.574105 0 0.483768 300 0.219094\r\n",
      "aex7sFCh-tA,137 0.574259 0 0.483586 300 0.218899\r\n",
      "aeDZVfGk7bk,137 0.574298 0 0.484021 300 0.219389\r\n",
      "a0urnJ9cs2s,137 0.574494 0 0.48259 300 0.218218\r\n",
      "a0xoEoG6b9c,137 0.574385 0 0.483135 300 0.218737\r\n",
      "azlUFirpDLQ,137 0.574366 0 0.483002 300 0.218506\r\n",
      "azshGovt8N0,137 0.574172 0 0.483409 300 0.218969\r\n",
      "azZOBpla-sA,137 0.574338 0 0.483273 300 0.218803\r\n",
      "az83Dh9SzQE,137 0.574274 0 0.483338 300 0.218808\r\n",
      "az7WWve4eJw,137 0.574225 0 0.483717 300 0.219033\r\n",
      "ajP5GeyxipU,137 0.57428 0 0.483423 300 0.218813\r\n",
      "ajYYuFO0MyU,137 0.574842 0 0.481848 300 0.217693\r\n",
      "ajRuw95DCkM,137 0.574405 0 0.483201 300 0.218673\r\n",
      "aj3a-xytyA0,137 0.574504 0 0.483083 300 0.218569\r\n",
      "arA35pnmAnE,137 0.57447 0 0.481541 300 0.217237\r\n",
      "arzwG4Naoyk,137 0.574381 0 0.483144 300 0.21874\r\n",
      "ar4YQ_DOcyk,137 0.57461 0 0.482481 300 0.218267\r\n",
      "argBwTHDDVI,137 0.574404 0 0.483211 300 0.21883\r\n",
      "arP0Jq35dws,137 0.574581 0 0.48221 300 0.217787\r\n",
      "arVhbQIB7FI,137 0.574813 0 0.481834 300 0.217732\r\n",
      "arEur8gF6ik,137 0.574427 0 0.483079 300 0.218651\r\n",
      "a54qawS9wCk,137 0.574414 0 0.483281 300 0.218819\r\n",
      "a5JsW77JhJU,137 0.574585 0 0.482652 300 0.218334\r\n",
      "aYdshSrW9T0,137 0.574454 0 0.48289 300 0.218462\r\n",
      "aYxDu6vfuSQ,137 0.574644 0 0.482192 300 0.217836\r\n",
      "aYjEIddVRQk,137 0.574242 0 0.476378 300 0.212566\r\n",
      "aY6aEHp04Wc,137 0.485571 0 0.392808 300 0.191648\r\n",
      "aYkpGvfGgv4,137 0.574008 0 0.483818 300 0.219216\r\n",
      "aOCtf6UEc8w,137 0.574383 0 0.483423 300 0.218835\r\n",
      "aOmRbSkPdVw,137 0.574276 0 0.483375 300 0.218731\r\n",
      "aOVPHKqKjyQ,137 0.574382 0 0.482619 300 0.218281\r\n",
      "aO29kiRkGOk,137 0.574404 0 0.483447 300 0.218896\r\n",
      "aOnlq3E1Nug,137 0.574625 0 0.482105 300 0.217869\r\n",
      "aySQzYi9KEg,137 0.574961 0 0.480844 300 0.216864\r\n",
      "aywseTNOiYI,137 0.574717 0 0.481583 300 0.217479\r\n",
      "ayPD5s4uiXM,137 0.574313 0 0.48333 300 0.218833\r\n",
      "ay7oVbQNiGI,137 0.574219 0 0.48368 300 0.218902\r\n",
      "avuoh1lRAKg,137 0.574275 0 0.483716 300 0.218977\r\n",
      "avjof2Izqq8,137 0.574467 0 0.482199 300 0.217921\r\n",
      "ab9jVHTUQsQ,137 0.574096 0 0.483754 300 0.219162\r\n",
      "abSLhN9TLEw,137 0.574524 0 0.482303 300 0.218085\r\n",
      "ab8V7MYQVyg,137 0.574934 0 0.480796 300 0.216892\r\n",
      "aaCeijVT2cA,137 0.575037 0 0.480257 300 0.216416\r\n",
      "aa7W8P_PkAY,137 0.574877 0 0.4813 300 0.217282\r\n",
      "aayUR43KzPI,137 0.574845 0 0.481025 300 0.217009\r\n",
      "aagve9y1NJY,137 0.574148 0 0.483808 300 0.219229\r\n",
      "aahydWsq_zQ,137 0.575054 0 0.479955 300 0.216322\r\n",
      "aaNR8FWJtSE,137 0.574161 0 0.483808 300 0.219034\r\n",
      "aa8t9_djFCs,137 0.574864 0 0.481123 300 0.217164\r\n",
      "aaq1OtdUAgc,137 0.574433 0 0.483128 300 0.218608\r\n",
      "aa_468eUE1o,137 0.57411 0 0.483731 300 0.21897\r\n",
      "aaQ489FcdAE,137 0.574526 0 0.482805 300 0.218413\r\n",
      "awCVWdqFxDs,137 0.574454 0 0.483054 300 0.218601\r\n",
      "awb9dareQmM,137 0.574681 0 0.482037 300 0.217956\r\n",
      "awnkrZfVSu0,137 0.574384 0 0.482679 300 0.218256\r\n",
      "awGEJJDYVGk,137 0.577057 0 0.46901 300 0.208594\r\n",
      "agw-ujSdX0A,137 0.574847 0 0.481062 300 0.217036\r\n",
      "agK1OkzW5Yg,137 0.574578 0 0.482457 300 0.218066\r\n",
      "agkoTtAp54U,137 0.574222 0 0.483833 300 0.219142\r\n",
      "aVdPh-RiNcc,137 0.574322 0 0.483036 300 0.218588\r\n",
      "aVNcweinmEM,137 0.574842 0 0.481418 300 0.217373\r\n",
      "aVuoBwZxcJ4,137 0.57423 0 0.483328 300 0.218789\r\n",
      "aKZxZpuqTUs,137 0.574161 0 0.483843 300 0.219128\r\n",
      "aKhM6zyL--k,137 0.574293 0 0.483526 300 0.218877\r\n",
      "aKmEJe1WaVQ,137 0.574518 0 0.482828 300 0.218502\r\n",
      "aKP0ibeiHT8,137 0.574254 0 0.483823 300 0.219056\r\n",
      "aK_uHc3SjHY,137 0.574286 0 0.483352 300 0.218883\r\n",
      "adHhqDnyZv8,137 0.574725 0 0.481613 300 0.217433\r\n",
      "adEy5j4XiJk,137 0.574465 0 0.483086 300 0.218606\r\n",
      "aMxLy5s3y8k,137 0.574253 0 0.483183 300 0.218557\r\n",
      "aMCC2ezBcxM,137 0.574133 0 0.483928 300 0.219233\r\n",
      "aMln3YY4J0E,137 0.574732 0 0.481272 300 0.217135\r\n",
      "aMvRqdvkTJo,137 0.57417 0 0.48371 300 0.21904\r\n",
      "a83NijNUlnM,137 0.57437 0 0.48332 300 0.218778\r\n",
      "a8Gh_efY1F8,137 0.574482 0 0.482982 300 0.218621\r\n",
      "axVAld8h_Lw,137 0.574651 0 0.481877 300 0.217726\r\n",
      "axRUQGQeBkE,137 0.574599 0 0.481499 300 0.217308\r\n",
      "axqtExFY5-s,137 0.574625 0 0.482619 300 0.218339\r\n",
      "ax6dilbzpWU,137 0.574564 0 0.482949 300 0.218534\r\n",
      "alSAxo29qms,137 0.57433 0 0.483494 300 0.219015\r\n",
      "al-oYMfdjzs,137 0.574044 0 0.483873 300 0.219156\r\n",
      "alfEjikOGFw,137 0.575481 0 0.477974 300 0.214827\r\n",
      "alMl2-3KfV8,137 0.574201 0 0.483816 300 0.219162\r\n",
      "alu4fcN2YDY,137 0.574274 0 0.483705 300 0.219157\r\n",
      "aluCLrmaoeM,137 0.57442 0 0.482833 300 0.218402\r\n",
      "alQYHjRxPFw,137 0.574501 0 0.482498 300 0.218069\r\n",
      "albkTiY7jRg,137 0.574443 0 0.482569 300 0.21798\r\n",
      "a32rtskZ9HI,137 0.574881 0 0.481377 300 0.217327\r\n",
      "a3FThSHYa3s,137 0.574378 0 0.483535 300 0.218998\r\n",
      "a3QRZd6xIxA,137 0.574733 0 0.48196 300 0.217831\r\n",
      "a3X4Jc06xzY,137 0.57451 0 0.482022 300 0.217713\r\n",
      "a7gsg1lFPjY,137 0.574425 0 0.482859 300 0.218484\r\n",
      "a78nWd0xCO0,137 0.575236 0 0.4776 300 0.214366\r\n",
      "a701SAZyJF4,137 0.5753 0 0.479406 300 0.215884\r\n",
      "a7jGKl192wI,137 0.574543 0 0.482357 300 0.218115\r\n",
      "a7sTljVHW6Q,137 0.574488 0 0.482862 300 0.218487\r\n",
      "a7GN1q4dH30,137 0.574745 0 0.481125 300 0.217139\r\n",
      "acCXxD5SyJs,137 0.574491 0 0.482516 300 0.218054\r\n",
      "acJyw6b63q4,137 0.57421 0 0.483714 300 0.219018\r\n",
      "acwqlw0TYtQ,137 0.574279 0 0.483626 300 0.218995\r\n",
      "aceU1El-9mg,137 0.574407 0 0.482966 300 0.21854\r\n",
      "acGOgOEhPog,137 0.574519 0 0.482751 300 0.218341\r\n",
      "ac_8oRMgDz0,137 0.574663 0 0.482431 300 0.218204\r\n",
      "acIL82JWyq4,137 0.574316 0 0.483584 300 0.219051\r\n",
      "aBfFtl1porE,137 0.574876 0 0.481547 300 0.217414\r\n",
      "aBLqpEhu_O8,137 0.57453 0 0.483151 300 0.21878\r\n",
      "aBdLzKU3ZW8,137 0.574501 0 0.482534 300 0.218197\r\n",
      "aBya230hlcs,137 0.575097 0 0.479964 300 0.216348\r\n",
      "aBEiuYSSEH0,137 0.574449 0 0.482901 300 0.218445\r\n",
      "atWaDoSyGgY,137 0.574615 0 0.482198 300 0.217945\r\n",
      "ath2TNOd1NU,137 0.57433 0 0.483244 300 0.218667\r\n",
      "atZuS5fn69c,137 0.57416 0 0.483983 300 0.219275\r\n",
      "atIbBTqPJwI,137 0.574435 0 0.482663 300 0.218377\r\n",
      "atJzEzwUQEs,137 0.574034 0 0.483733 300 0.219123\r\n",
      "at48Zq6OdG0,137 0.574429 0 0.483212 300 0.218719\r\n",
      "aPE-vmZFR4I,137 0.574359 0 0.483024 300 0.21857\r\n",
      "aPN-7CnRjxo,137 0.574357 0 0.483406 300 0.218763\r\n",
      "aPAa2sfhS7k,137 0.57456 0 0.482948 300 0.218514\r\n",
      "ahOvnUn1o5g,137 0.574126 0 0.48418 300 0.219332\r\n",
      "ahLyVqSRicE,137 0.57459 0 0.482415 300 0.218247\r\n",
      "ahQ7rgXWtrM,137 0.574214 0 0.48387 300 0.219286\r\n",
      "ah4Z7LadZx0,137 0.574337 0 0.483445 300 0.21885\r\n",
      "ahWHi1iqvAc,137 0.574724 0 0.481951 300 0.217789\r\n",
      "ahct5yzUtdE,137 0.574608 0 0.482706 300 0.218444\r\n",
      "ahgYxUhBEU4,137 0.574175 0 0.483679 300 0.219183\r\n",
      "a-P0p_UtagM,137 0.574166 0 0.483772 300 0.218994\r\n",
      "a-11dtG7aK4,137 0.574338 0 0.483376 300 0.218959\r\n",
      "a-0aq-U69tk,137 0.57421 0 0.483944 300 0.219311\r\n",
      "a-ghIXQAfys,137 0.57428 0 0.48359 300 0.218975\r\n",
      "aJkcW-UloFg,137 0.574169 0 0.483762 300 0.219098\r\n",
      "aJRYw8I1IKE,137 0.574147 0 0.483708 300 0.218968\r\n",
      "aJI_a-SdrhE,137 0.574714 0 0.482272 300 0.218017\r\n",
      "aJbsdoDHUrI,137 0.574374 0 0.483561 300 0.219096\r\n",
      "aT8ZoRLiJf0,137 0.57468 0 0.482719 300 0.218391\r\n",
      "aTu2S04Zizo,137 0.574214 0 0.483594 300 0.219056\r\n",
      "aTn_8hd3xN0,137 0.574496 0 0.4827 300 0.21831\r\n",
      "aTTCbXAqVBE,137 0.574863 0 0.481656 300 0.217563\r\n",
      "aTtFjajpi3Y,137 0.574409 0 0.482663 300 0.218252\r\n",
      "aTh9_IrguMo,137 0.574556 0 0.481462 300 0.217253\r\n",
      "aTaSLxjvjnY,137 0.569279 0 0.447827 300 0.192266\r\n",
      "aslxfM0T8No,137 0.573987 0 0.483963 300 0.219258\r\n",
      "asYb6iDz_kM,137 0.574684 0 0.482172 300 0.217948\r\n",
      "asJ0IUZ0eDY,137 0.574253 0 0.483481 300 0.21896\r\n",
      "asef1m3NUy4,137 0.574854 0 0.481791 300 0.21758\r\n",
      "aszZlMhmhNw,137 0.574118 0 0.483381 300 0.218836\r\n",
      "aswW9bLubYM,137 0.574312 0 0.483187 300 0.218651\r\n",
      "as4klFxdMyo,137 0.584196 0 0.423493 300 0.178803\r\n",
      "aQdZtz90Yzw,137 0.574315 0 0.483427 300 0.21891\r\n",
      "aQ2B2BTWfJU,137 0.574397 0 0.483132 300 0.218759\r\n",
      "a9VnNZH1X2c,137 0.574324 0 0.48334 300 0.218761\r\n",
      "a9QCiMuyVjQ,137 0.574342 0 0.481893 300 0.217356\r\n",
      "a9093ExzsvM,137 0.57418 0 0.483564 300 0.218883\r\n",
      "a9PEzKDNNW4,137 0.574179 0 0.483785 300 0.219077\r\n",
      "a9E5Bxbv-u4,137 0.574429 0 0.48305 300 0.218563\r\n",
      "a9JWkLMJjro,137 0.574347 0 0.483309 300 0.218813\r\n",
      "a91HKYicQ1g,137 0.574416 0 0.483398 300 0.218961\r\n",
      "a91Nb-aSz0g,137 0.574228 0 0.483896 300 0.219254\r\n",
      "a9i5yixsJbk,137 0.574156 0 0.483778 300 0.219131\r\n",
      "a9DEPNkY98o,137 0.574271 0 0.483558 300 0.21894\r\n",
      "aR6rdYh_UpQ,137 0.574598 0 0.4824 300 0.218156\r\n",
      "aRGAnD12qdw,137 0.574547 0 0.482612 300 0.218288\r\n",
      "aRb7xGc92aE,137 0.574138 0 0.483879 300 0.219186\r\n",
      "aZ0_py3k6AM,137 0.574324 0 0.483182 300 0.218829\r\n",
      "aZYcnc1tAGs,137 0.574226 0 0.483385 300 0.218751\r\n",
      "aZMpTfhv71I,137 0.574814 0 0.479977 300 0.216236\r\n",
      "aZsy2kq3Va4,137 0.574469 0 0.482766 300 0.218315\r\n",
      "aZYmZCczxfc,137 0.574486 0 0.48281 300 0.218386\r\n",
      "aZwr_DBs15g,137 0.545629 0 0.426143 300 0.183241\r\n",
      "aEZG-eTGRkI,137 0.574268 0 0.483521 300 0.21897\r\n",
      "aE4ESio-d2k,137 0.574439 0 0.4831 300 0.218621\r\n",
      "aERzneFiiCY,137 0.574647 0 0.482033 300 0.217789\r\n",
      "aETjM7dTWSM,137 0.574529 0 0.482719 300 0.218345\r\n",
      "aEgo8yFpiPg,137 0.574362 0 0.482724 300 0.21834\r\n",
      "aE_4rX3fKC0,137 0.574945 0 0.481038 300 0.217164\r\n",
      "aEbYdJCy9GI,137 0.574523 0 0.482643 300 0.218309\r\n",
      "aFynKC57CfI,137 0.57409 0 0.483429 300 0.218852\r\n",
      "aFjuOD6n_qU,137 0.574459 0 0.482607 300 0.218121\r\n",
      "aF8202ZbqVc,137 0.574365 0 0.483298 300 0.218736\r\n",
      "aFm42q8b6GA,137 0.574404 0 0.483206 300 0.218531\r\n",
      "aFt0iNZhnDQ,137 0.575325 0 0.479073 300 0.215609\r\n",
      "aFYyIqpyLqE,137 0.575266 0 0.47917 300 0.215747\r\n",
      "a6lkhbf_HAc,137 0.574748 0 0.482056 300 0.217834\r\n",
      "a6RiChF6JW4,137 0.574309 0 0.483266 300 0.218863\r\n",
      "a6HE939n-Jk,137 0.574882 0 0.482084 300 0.217974\r\n",
      "a6v9tIEQRXE,137 0.57419 0 0.483729 300 0.219086\r\n",
      "a6sHMAd5oxY,137 0.574662 0 0.482084 300 0.217822\r\n",
      "a6z5wMJ9IRk,137 0.574353 0 0.483516 300 0.218816\r\n",
      "a1PQCCz-Kw8,137 0.574323 0 0.483557 300 0.218936\r\n",
      "a1djabBX0EQ,137 0.574636 0 0.482427 300 0.218049\r\n",
      "a1sIgQTCapM,137 0.574124 0 0.484044 300 0.219377\r\n",
      "a1mopKL1uvo,137 0.574396 0 0.483507 300 0.218879\r\n",
      "a1_OQtN59KI,137 0.574367 0 0.483408 300 0.218919\r\n",
      "aomaneVgUs0,137 0.574237 0 0.483748 300 0.219038\r\n",
      "ao9oox4OiGU,137 0.574211 0 0.483553 300 0.218878\r\n",
      "anyiuVZiogk,137 0.57441 0 0.48339 300 0.218905\r\n",
      "anujpzVRneY,137 0.574631 0 0.482241 300 0.218044\r\n",
      "anIp_GHNtKA,137 0.574102 0 0.483961 300 0.219294\r\n",
      "anWlXiCR01Y,137 0.574588 0 0.481985 300 0.2177\r\n",
      "and39TYJrEI,137 0.574377 0 0.482685 300 0.218236\r\n",
      "an4yPkF9xx8,137 0.574525 0 0.483076 300 0.218616\r\n"
     ]
    }
   ],
   "source": [
    "!cat notebooks/Bal_SamplePredictions.csv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VGGish Audioset & Auio embedding Tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
